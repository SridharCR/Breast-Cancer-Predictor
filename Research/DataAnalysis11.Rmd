---
title: "Data Analysis"
author: "Sridhar"
date: "28 January 2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r}
#install.packages("ggplot2")
#install.packages("ggvis")
#install.packages("mice")
library(ggplot2)
library(ggvis)
library(knitr)
library(mice)
library(caret)
library(doParallel) 
```
## Load the Data
Breast Cancer Wisconsin(Diagnosis) data is loaded and the column names are defined based on the attribute information.

### Dataset 1
The outcome variable is the "classes" and it has following category of data

* Malignant or
* Benign breast mass

The phenotypes for characterization are
* Sample ID (code number)
* Clump thickness
* Uniformity of cell size
* Uniformity of cell shape
* Marginal adhesion
* Single epithelial cell size
* Number of bare nuclei
* Bland chromatin
* Number of normal nuclei
* Mitosis
* Classes, i.e. diagnosis


```{r}
diagnosis_data <- read.csv("~/Desktop/BreastCancer/Data/breast-cancer-wisconsin.data.csv", header = FALSE)
colnames(diagnosis_data) <- c("sample_code_number", "clump_thickness", "uniformity_of_cell_size", "uniformity_of_cell_shape", "marginal_adhesion", "single_epithelial_cell_size", 
                       "bare_nuclei", "bland_chromatin", "normal_nucleoli", "mitosis", "classes")

```


```{r}
# impute missing data

diagnosis_data[,2:10] <- apply(diagnosis_data[, 2:10], 2, function(x) as.numeric(as.character(x)))

dataset_impute <- mice(diagnosis_data[, 2:10],  print = FALSE)
diagnosis_data <- cbind(diagnosis_data[, 11, drop = FALSE], mice::complete(dataset_impute, 1))

diagnosis_data$classes <- as.factor(diagnosis_data$classes)

# how many benign and malignant cases are there?
summary(diagnosis_data$classes)

```
The data is presented below.


```{r }
head(diagnosis_data)
```

The properties of data are given,

```{r}
str(diagnosis_data)
```

```{r}
summary(diagnosis_data)
```

### Dataset 2
The outcome variable is the "classes" and it has following category of data
Attribute Information:

1) ID number 
2) Diagnosis (M = malignant, B = benign) 
3-32) 

Ten real-valued features are computed for each cell nucleus: 

a) radius (mean of distances from center to points on the perimeter) 
b) texture (standard deviation of gray-scale values) 
c) perimeter 
d) area 
e) smoothness (local variation in radius lengths) 
f) compactness (perimeter^2 / area - 1.0) 
g) concavity (severity of concave portions of the contour) 
h) concave points (number of concave portions of the contour) 
i) symmetry 
j) fractal dimension ("coastline approximation" - 1)

```{r}
diagnosis_data_2 <- read.csv("~/Desktop/BreastCancer/Data/wdbc.data.csv", header = FALSE)

phenotypes <- rep(c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension"), 3)
types <- rep(c("mean", "se", "largest_worst"), each = 10)

colnames(diagnosis_data_2) <- c("ID", "diagnosis", paste(phenotypes, types, sep = "_"))
head(diagnosis_data_2)

```

```{r}
str(diagnosis_data_2)
```

```{r}
diagnosis_data_3 <- read.csv("~/Desktop/BreastCancer/Data/wpbc.data.csv", header = FALSE)

colnames(diagnosis_data_3) <- c("ID", "outcome", "time", paste(phenotypes, types, sep = "_"), "tumor_size", "lymph_node_status")
diagnosis_data_3[diagnosis_data_3 == "?"] <- NA
head(diagnosis_data_3)

```


```{r}
diagnosis_data_3[,3:35] <- apply(diagnosis_data_3[,3:35], 2, function(x) as.numeric(as.character(x)))
dataset_impute <- mice(diagnosis_data_3[,3:35],  print = FALSE)
diagnosis_data_3 <- cbind(diagnosis_data_3[, 2, drop = FALSE], mice::complete(dataset_impute, 1))

# how many recurring and non-recurring cases are there?
summary(diagnosis_data_3$outcome)
head(diagnosis_data_3)
```




```{r}

# plotting theme

library(ggplot2)

my_theme <- function(base_size = 12, base_family = "sans"){
  theme_minimal(base_size = base_size, base_family = base_family) +
  theme(
    axis.text = element_text(size = 12),
    axis.text.x = element_text(angle = 0, vjust = 1, hjust = 1),
    axis.title = element_text(size = 14),
    panel.grid.major = element_line(color = "grey"),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "aliceblue"),
    strip.background = element_rect(fill = "navy", color = "navy", size = 2),
    strip.text = element_text(face = "bold", size = 12, color = "white"),
    legend.position = "right",
    legend.justification = "top", 
    legend.background = element_blank(),
    panel.border = element_rect(color = "grey", fill = NA, size = 1)
  )
}

theme_set(my_theme())
```



```{r}
# function for PCA plotting
library(pcaGoPromoter)
library(ellipse)

pca_func <- function(data, groups, title, print_ellipse = TRUE) {
  
  # perform pca and extract scores
  pcaOutput <- pca(data, printDropped = FALSE, scale = TRUE, center = TRUE)
  pcaOutput2 <- as.data.frame(pcaOutput$scores)
  
  # define groups for plotting
  pcaOutput2$groups <- groups
  
  # when plotting samples calculate ellipses for plotting (when plotting features, there are no replicates)
  if (print_ellipse) {
    
    centroids <- aggregate(cbind(PC1, PC2) ~ groups, pcaOutput2, mean)
    conf.rgn  <- do.call(rbind, lapply(unique(pcaOutput2$groups), function(t)
      data.frame(groups = as.character(t),
                 ellipse(cov(pcaOutput2[pcaOutput2$groups == t, 1:2]),
                       centre = as.matrix(centroids[centroids$groups == t, 2:3]),
                       level = 0.95),
                 stringsAsFactors = FALSE)))
    
    plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
      geom_polygon(data = conf.rgn, aes(fill = groups), alpha = 0.2) +
      geom_point(size = 2, alpha = 0.6) + 
      scale_color_brewer(palette = "Set1") +
      labs(title = title,
           color = "",
           fill = "",
           x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
           y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
    
  } else {
    
    # if there are fewer than 10 groups (e.g. the predictor classes) I want to have colors from RColorBrewer
    if (length(unique(pcaOutput2$groups)) <= 10) {
      
      plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
        geom_point(size = 2, alpha = 0.6) + 
        scale_color_brewer(palette = "Set1") +
        labs(title = title,
             color = "",
             fill = "",
             x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
             y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
      
    } else {
      
      # otherwise use the default rainbow colors
      plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
        geom_point(size = 2, alpha = 0.6) + 
        labs(title = title,
             color = "",
             fill = "",
             x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
             y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
      
    }
  }
  
  return(plot)
  
}
```


```{r}
library(gridExtra)
library(grid)
p1 <- pca_func(data = t(diagnosis_data[, 2:10]), groups = as.character(diagnosis_data$classes), title = "Breast cancer dataset 1: Samples")
p2 <- pca_func(data = diagnosis_data[, 2:10], groups = as.character(colnames(diagnosis_data[, 2:10])), title = "Breast cancer dataset 1: Features", print_ellipse = FALSE)
plot(p1)
plot(p2)
```



```{r}
h_1 <- hclust(dist(t(diagnosis_data[, 2:10]), method = "euclidean"), method = "complete")
plot(h_1)
```



```{r}
library(tidyr)
diagnosis_data_gather <- diagnosis_data %>%
  gather(measure, value, clump_thickness:mitosis)

ggplot(data = diagnosis_data_gather, aes(x = value, fill = classes, color = classes)) +
  geom_density(alpha = 0.3, size = 1) +
  geom_rug() +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  facet_wrap( ~ measure, scales = "free_y", ncol = 3)
```



```{r}
p1 <- pca_func(data = t(diagnosis_data_2[, 3:32]), groups = as.character(diagnosis_data_2$diagnosis), title = "Breast cancer dataset 2: Samples")
p2 <- pca_func(data = diagnosis_data_2[, 3:32], groups = as.character(colnames(diagnosis_data_2[, 3:32])), title = "Breast cancer dataset 2: Features", print_ellipse = FALSE)
plot(p1)
plot(p2)
```

```{r}
h_2 <- hclust(dist(t(diagnosis_data_2[, 3:32]), method = "euclidean"), method = "complete")
plot(h_2)
```




```{r}
p1 <- pca_func(data = t(diagnosis_data_3[, 2:34]), groups = as.character(diagnosis_data_3$outcome), title = "Breast cancer dataset 3: Samples")
p2 <- pca_func(data = diagnosis_data_3[, 2:34], groups = as.character(colnames(diagnosis_data_3[, 2:34])), title = "Breast cancer dataset 3: Features", print_ellipse = FALSE)
plot(p1)
plot(p2)
```



```{r}
h_3 <- hclust(dist(t(diagnosis_data_3[,2:34]), method = "euclidean"), method = "complete")
plot(h_3)
```
```{r}
diagnosis_data_3_gather <- diagnosis_data_3 %>%
  gather(measure, value, time:lymph_node_status)

ggplot(data = diagnosis_data_3_gather, aes(x = value, fill = outcome, color = outcome)) +
  geom_density(alpha = 0.3, size = 1) +
  geom_rug() +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  facet_wrap( ~ measure, scales = "free_y", ncol = 3)
```




```{r}
# parallel processing
registerDoParallel()

# prepare training scheme
control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

feature_imp <- function(model, title) {
  
  # estimate variable importance
  importance <- varImp(model, scale = TRUE)
  
  # prepare dataframes for plotting
  importance_df_1 <- importance$importance
  importance_df_1$group <- rownames(importance_df_1)
  
  importance_df_2 <- importance_df_1
  importance_df_2$Overall <- 0
  
  importance_df <- rbind(importance_df_1, importance_df_2)
  
  plot <- ggplot() +
    geom_point(data = importance_df_1, aes(x = Overall, y = group, color = group), size = 2) +
    geom_path(data = importance_df, aes(x = Overall, y = group, color = group, group = group), size = 1) +
    theme(legend.position = "none") +
    labs(
      x = "Importance",
      y = "",
      title = title,
      subtitle = "Scaled feature importance",
      caption = "\nDetermined with Random Forest and
      repeated cross validation (10 repeats, 10 times)"
    )
  
  return(plot)
  
}
```



```{r}
# train the model
set.seed(27)
imp_1 <- train(classes ~ ., data = diagnosis_data, method = "rf", preProcess = c("scale", "center"), trControl = control)
p1 <- feature_imp(imp_1, title = "Breast cancer dataset 1")
set.seed(27)
imp_2 <- train(diagnosis ~ ., data = diagnosis_data_2[, -1], method = "rf", preProcess = c("scale", "center"), trControl = control)
p2 <- feature_imp(imp_2, title = "Breast cancer dataset 2")
set.seed(27)
imp_3 <- train(outcome ~ ., data = diagnosis_data_3, method = "rf", preProcess = c("scale", "center"), trControl = control)
p3 <- feature_imp(imp_3, title = "Breast cancer dataset 3")
grid.arrange(p1, p2, p3, ncol = 3, widths = c(0.3, 0.35, 0.35))
```
Correlation

```{r}
library(caret)
set.seed(27)
diagnosis_data_index <- createDataPartition(diagnosis_data$classes, p = 0.7, list = FALSE)
diagnosis_data_train <- diagnosis_data[diagnosis_data_index, ]
diagnosis_data_test  <- diagnosis_data[-diagnosis_data_index, ]
```

Dataset 2
```{r}
set.seed(27)
diagnosis_data_2_index <- createDataPartition(diagnosis_data_2$diagnosis, p = 0.7, list = FALSE)
diagnosis_data_2_train <- diagnosis_data_2[diagnosis_data_2_index, ]
diagnosis_data_2_test  <- diagnosis_data_2[-diagnosis_data_2_index, ]
```

Dataset 3
```{r}
set.seed(27)
diagnosis_data_3_index <- createDataPartition(diagnosis_data_3$outcome, p = 0.7, list = FALSE)
diagnosis_data_3_train <- diagnosis_data_3[diagnosis_data_3_index, ]
diagnosis_data_3_test  <- diagnosis_data_3[-diagnosis_data_3_index, ]
```

```{r}
library(corrplot)

# calculate correlation matrix
corMatMy <- cor(diagnosis_data_train[, -1])
corrplot(corMatMy, order = "hclust")
```



```{r}
corMatMy <- cor(diagnosis_data_2_train[, 3:32])
corrplot(corMatMy, order = "hclust")
```

```{r}
corMatMy <- cor(diagnosis_data_3_train[, -1])
corrplot(corMatMy, order = "hclust", number.cex=1)
```
```{r}
highlyCor <- colnames(diagnosis_data_3_train[, -1])[findCorrelation(corMatMy, cutoff = 0.7, verbose = TRUE)]
```
```{r}
highlyCor
```

```{r}
diagnosis_data_3_cor <- diagnosis_data_3_train[, which(!colnames(diagnosis_data_3_train) %in% highlyCor)]
```


Recursive Feature Elimination (RFE)
Another way to choose features is with Recursive Feature Elimination. RFE uses a Random Forest algorithm to test combinations of features and rate each with an accuracy score. The combination with the highest score is usually preferential.


```{r}
# ensure the results are repeatable
set.seed(7)
# define the control using a random forest selection function with cross validation
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# run the RFE algorithm
results_1 <- rfe(x = diagnosis_data_train[, -1], y = diagnosis_data_train$classes, sizes = c(1:9), rfeControl = control)

# chosen features
predictors(results_1)
```

```{r}
# subset the chosen features
diagnosis_data_rfe <- diagnosis_data_train[, c(1, which(colnames(diagnosis_data_train) %in% predictors(results_1)))]
```

```{r}
set.seed(7)
results_2 <- rfe(x = diagnosis_data_2_train[, -c(1, 2)], y = as.factor(diagnosis_data_2_train$diagnosis), sizes = c(1:30), rfeControl = control)

predictors(results_2)
```

```{r}
diagnosis_data_2_rfe <- diagnosis_data_2_train[, c(2, which(colnames(diagnosis_data_2_train) %in% predictors(results_2)))]
```

```{r}
set.seed(7)
results_3 <- rfe(x = diagnosis_data_3_train[,-1], y = as.factor(diagnosis_data_3_train$outcome), sizes = c(1:33), rfeControl = control)

predictors(results_2)
```

```{r}
diagnosis_data_3_rfe <- diagnosis_data_3_train[, c(1, which(colnames(diagnosis_data_3_train) %in% predictors(results_3)))]
```

```{r}
library(dplyr)

ga_ctrl <- gafsControl(functions = rfGA, # Assess fitness with RF
                       method = "cv",    # 10 fold cross validation
                       genParallel = TRUE, # Use parallel programming
                       allowParallel = TRUE)
```

```{r}
lev <- c("malignant", "benign")     # Set the levels

set.seed(27)
model_1 <- gafs(x = diagnosis_data_train[, -1], y = diagnosis_data_train$classes,
                   iters = 10, # generations of algorithm
                   popSize = 5, # population size for each generation
                   levels = lev,
                   gafsControl = ga_ctrl)
```

```{r}
plot(model_1) # Plot mean fitness (AUC) by generation
```

```{r}
model_1$ga$final
```

```{r}
diagnosis_data_ga <- diagnosis_data_train[, c(1, which(colnames(diagnosis_data_train) %in% model_1$ga$final))]
```


```{r}
lev <- c("M", "B")

set.seed(27)
model_2 <- gafs(x = diagnosis_data_2_train[, -c(1, 2)], y = diagnosis_data_2_train$diagnosis,
                   iters = 10, # generations of algorithm
                   popSize = 5, # population size for each generation
                   levels = lev,
                   gafsControl = ga_ctrl)
```


```{r}
plot(model_2)
```

```{r}
model_2$ga$final
diagnosis_data_2_ga <- diagnosis_data_2_train[, c(2, which(colnames(diagnosis_data_2_train) %in% model_2$ga$final))]
```

```{r}

lev <- c("R", "N")

set.seed(27)
model_3 <- gafs(x = diagnosis_data_3_train[, -1], y = diagnosis_data_3_train$outcome,
                   iters = 10, # generations of algorithm
                   popSize = 5, # population size for each generation
                   levels = lev,
                   gafsControl = ga_ctrl)
```

```{r}
plot(model_3)
```

```{r}
model_3$ga$final
```

```{r}
diagnosis_data_3_ga <- diagnosis_data_3_train[, c(1, which(colnames(diagnosis_data_3_train) %in% model_3$ga$final))]
```
Model comparison

```{r}

```

