---
title: "Breast Cancer Prediction"
author: "Rohit"
date: "December 7, 2017"
output: 
  html_document:
      theme: lumen
      toc: true
      html_notebook: default

---

##Using Breast Cancer(Wisconsin) Diagnostic data set for predictive analysis

The dataset is available on Kaggle (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = F,warning = F)
```

##Load the requried Libraries

```{r}
library(dplyr)
library(ggplot2)
library(corrplot)
library(gridExtra)
library(lattice)
library(C50)
library(caret)
library(purrr)
library(ggfortify)
library(gmodels)
library(nnet)
library(vcd)
library(NeuralNetTools)
```

##Read the data

```{r}
cancer_data <- read.csv("~/Desktop/BreastCancer/Research/data.csv")
```

## Understand the dataset and get it corrected

Before doing any analysis lets check for the missing values in the columns

```{r}
map_int(cancer_data, function(.x) sum(is.na(.x)))
#As per the result column 'X' is the only column which has the value 'NA'.
#This check is defintely most important step before starting analysis.
```
Get the dataset corrected by removing the 'X' column as it is the only column containing 'NA' values and also 'id' column as it represents the patient identifier and not required for the analysis.

```{r}
cancer_data<- cancer_data[,-c(1,33)]
dim(cancer_data)
# We will now perform the analysis on 31 columns
```
## Find correlation

For any analysis to be robust it is good to remove  highly correlated predictors.
```{r}
# Remove the factorial column 'diagnosis' to find the correlation between numerical columns.
data_corr<- cor(cancer_data[,-1])
corrplot::corrplot(data_corr, order = "hclust", tl.cex = 1, addrect = 8)
```

It is quite clear that there are few variables that are correlated. So let's transform the data by removing highly correlated ones using the caret package.

## Transformation of data
```{r}
cancer_data2<- cancer_data[,-findCorrelation(data_corr,cutoff = 0.9)]

#Number of columns for our new data frame

ncol(cancer_data2)

```
So now our new data frame cancer_data2 is 10 variables shorter.

##Preprocessing of data using PCA

To get more clarity let's do the preprocessing on data before and after transformation

1. PCA analysis on untransformed data.
   To do so, we will need to remove the diagnosis variable then will scale and center the    variables.
```{r}
prepro_pca_cancerdata<- prcomp(cancer_data[,-1],scale = TRUE, center = TRUE)
summary(prepro_pca_cancerdata)

# Calculate the proportion of variance explained

pca_data_var<- prepro_pca_cancerdata$sdev^2
pv_data<-pca_data_var/sum(pca_data_var)
cum_pv<- cumsum(pv_data)
pv_table<- tibble(comp= seq(1:ncol(cancer_data[-1])),pv_data,cum_pv)

#Let's plot the graph

ggplot(pv_table,aes(x=comp,y=cum_pv))+ geom_point(col= "red")+ geom_abline(intercept = 0.95,slope = 0)
```

This represents that 10 PC's are required to explain 95% of the variance

2.PCA analysis on the Transformed data.
```{r}
prepro_pca_cancerdata2<- prcomp(cancer_data2,scale = TRUE, center = TRUE)
summary(prepro_pca_cancerdata2)

# Calculate the proportion of variance explained
pca_data_var2<- prepro_pca_cancerdata2$sdev^2
pv_data2<-pca_data_var2/sum(pca_data_var2)
cum_pv2<- cumsum(pv_data2)
pv_table2<- tibble(comp= seq(1:ncol(cancer_data2)),pv_data2,cum_pv2)

#Let's plot the graph

ggplot(pv_table2,aes(x=comp,y=cum_pv2))+ geom_point(col= "red")+ geom_abline(intercept = 0.95,slope = 0)
```


This represents that 10 PC's are required to explain 95% of the variance.

Let's Visualize which variable are the most influential on the first 2 components

```{r}
autoplot(prepro_pca_cancerdata2, data = cancer_data,  colour = 'diagnosis',
                    loadings = FALSE, loadings.label = TRUE, loadings.colour = "blue")

```

##Prediction of data

```{r}
pred_cancerdata<- predict(prepro_pca_cancerdata2,newdata = cancer_data2)
```
Combine the removed 'diagnosis' column to the predicted data

```{r}
cancer_data2<- cbind(diagnosis= cancer_data[,1],pred_cancerdata)
#Convert the matrix to data frame
cancer_data2 = data.frame(cancer_data2)
str(cancer_data2)
# Convert diagnosis column into factorial
cancer_data2$diagnosis = as.factor(cancer_data2$diagnosis)

```
##Data Modeling {.tabset}

Create the train and test data.

```{r}
# Store 80% of the random dataset into the variable
cancer_data2_Index <- createDataPartition(cancer_data2$diagnosis,p= 0.8, list = FALSE)

# Assign these 80% of the data to the train dataset and rest 20% into test dataset.
cancer_data2_train <- cancer_data2[cancer_data2_Index,]
cancer_data2_test <- cancer_data2[-cancer_data2_Index,]
```
###C5.0 Model

```{r}
model_c50<-C5.0(diagnosis ~ ., data=cancer_data2_train,
                      trials=10,                  # creating max 10 weak learners steps
                      control = C5.0Control      # parameter control list. May specify separately
                        ( 
                           noGlobalPruning = FALSE,
                           CF=0.50,       # Less the value, more drastic the pruning.
                           minCases=10,   # Min cases per leaf-node
                           sample = 0.80, # Take 80% sample for training. Rest 20% used for testing 
                           winnow=FALSE,            # TRUE may make it more general
                           earlyStopping=TRUE       # boosting will be stopped early
                        ))

```
####Plot the model

```{r}
plot(model_c50,type="simple",gpar = gpar(fontsize = 5), drop_terminal = T, tnex=1)
```

####Prediction

Make predictions from the model created above
```{r}
predict_c50<- predict(model_c50,cancer_data2_test,type="class")

#Plot the confusion Matrix

confusionMatrix(predict_c50, cancer_data2_test$diagnosis)

#Draw the Crosstable

CrossTable(cancer_data2_test$diagnosis,predict_c50,prop.chisq = T,prop.c = F,prop.r = F,dnn = c("Actual Diagnosis","Predict Diagnosis"))
```

####Accuracy

```{r}
df<- data.frame(predicted=predict_c50, actual=cancer_data2_test$diagnosis)
table(df$actual, df$predicted, dnn=c("Actual","Predicted"))
accuracy<-sum(as.character(df$actual) == as.character(df$predicted))/nrow(df)
accuracy
```

###Neural Network Model

```{r}
model_nnet<-nnet(diagnosis ~. ,
                 data= cancer_data2_train,
                 size=8
)

# Plot a neural interpretation diagram for a neural network object
plotnet(model_nnet, cex_val =.8,max_sp=T,circle_cex=5,circle_col = 'red')

#Relative importance of input variables in neural networks using Garson's algorithm
garson(model_nnet)

olden(model_nnet)

```

Here both the positve and negative value represents relative contibutions of each connection weight among the variables


####Predict
```{r}
predict_nnet<- predict(model_nnet,cancer_data2_test,type = "class")
```
####Draw the crosstable
```{r}
CrossTable(cancer_data2_test$diagnosis,predict_nnet,prop.chisq = F,prop.r = F,prop.c = F,dnn =c("Actual Diagnosis","Predict Diagnosis"))
```

#### Accurancy

```{r}
table(df$actual, df$predicted, dnn=c("Actual","Predicted"))
accuracy<-sum(as.character(df$actual) == as.character(df$predicted))/nrow(df)
accuracy
```

##Conclusion

Neural network provides better prediction than the C5.0 decision tree.